{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b29811c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-09-17</th>\n",
       "      <td>465.864014</td>\n",
       "      <td>468.174011</td>\n",
       "      <td>452.421997</td>\n",
       "      <td>457.334015</td>\n",
       "      <td>457.334015</td>\n",
       "      <td>21056800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-09-18</th>\n",
       "      <td>456.859985</td>\n",
       "      <td>456.859985</td>\n",
       "      <td>413.104004</td>\n",
       "      <td>424.440002</td>\n",
       "      <td>424.440002</td>\n",
       "      <td>34483200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-09-19</th>\n",
       "      <td>424.102997</td>\n",
       "      <td>427.834991</td>\n",
       "      <td>384.532013</td>\n",
       "      <td>394.795990</td>\n",
       "      <td>394.795990</td>\n",
       "      <td>37919700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-09-20</th>\n",
       "      <td>394.673004</td>\n",
       "      <td>423.295990</td>\n",
       "      <td>389.882996</td>\n",
       "      <td>408.903992</td>\n",
       "      <td>408.903992</td>\n",
       "      <td>36863600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-09-21</th>\n",
       "      <td>408.084991</td>\n",
       "      <td>412.425995</td>\n",
       "      <td>393.181000</td>\n",
       "      <td>398.821014</td>\n",
       "      <td>398.821014</td>\n",
       "      <td>26580100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-03</th>\n",
       "      <td>16688.847656</td>\n",
       "      <td>16760.447266</td>\n",
       "      <td>16622.371094</td>\n",
       "      <td>16679.857422</td>\n",
       "      <td>16679.857422</td>\n",
       "      <td>13903079207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-04</th>\n",
       "      <td>16680.205078</td>\n",
       "      <td>16964.585938</td>\n",
       "      <td>16667.763672</td>\n",
       "      <td>16863.238281</td>\n",
       "      <td>16863.238281</td>\n",
       "      <td>18421743322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-05</th>\n",
       "      <td>16863.472656</td>\n",
       "      <td>16884.021484</td>\n",
       "      <td>16790.283203</td>\n",
       "      <td>16836.736328</td>\n",
       "      <td>16836.736328</td>\n",
       "      <td>13692758566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-06</th>\n",
       "      <td>16836.472656</td>\n",
       "      <td>16991.994141</td>\n",
       "      <td>16716.421875</td>\n",
       "      <td>16951.968750</td>\n",
       "      <td>16951.968750</td>\n",
       "      <td>14413662913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-07</th>\n",
       "      <td>16948.787109</td>\n",
       "      <td>16975.017578</td>\n",
       "      <td>16929.378906</td>\n",
       "      <td>16933.265625</td>\n",
       "      <td>16933.265625</td>\n",
       "      <td>13310965760</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3035 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Open          High           Low         Close  \\\n",
       "Date                                                                 \n",
       "2014-09-17    465.864014    468.174011    452.421997    457.334015   \n",
       "2014-09-18    456.859985    456.859985    413.104004    424.440002   \n",
       "2014-09-19    424.102997    427.834991    384.532013    394.795990   \n",
       "2014-09-20    394.673004    423.295990    389.882996    408.903992   \n",
       "2014-09-21    408.084991    412.425995    393.181000    398.821014   \n",
       "...                  ...           ...           ...           ...   \n",
       "2023-01-03  16688.847656  16760.447266  16622.371094  16679.857422   \n",
       "2023-01-04  16680.205078  16964.585938  16667.763672  16863.238281   \n",
       "2023-01-05  16863.472656  16884.021484  16790.283203  16836.736328   \n",
       "2023-01-06  16836.472656  16991.994141  16716.421875  16951.968750   \n",
       "2023-01-07  16948.787109  16975.017578  16929.378906  16933.265625   \n",
       "\n",
       "               Adj Close       Volume  \n",
       "Date                                   \n",
       "2014-09-17    457.334015     21056800  \n",
       "2014-09-18    424.440002     34483200  \n",
       "2014-09-19    394.795990     37919700  \n",
       "2014-09-20    408.903992     36863600  \n",
       "2014-09-21    398.821014     26580100  \n",
       "...                  ...          ...  \n",
       "2023-01-03  16679.857422  13903079207  \n",
       "2023-01-04  16863.238281  18421743322  \n",
       "2023-01-05  16836.736328  13692758566  \n",
       "2023-01-06  16951.968750  14413662913  \n",
       "2023-01-07  16933.265625  13310965760  \n",
       "\n",
       "[3035 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import pandas_ta as ta\n",
    "#data = yf.download(tickers = '^RUI', start = '2012-03-11',end = '2022-07-10')\n",
    "data = yf.download(tickers='BTC-usd', priod= 'max',interval='1d')\n",
    "#data.head(10)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68e700e1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ta' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Adding indicators\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m data[\u001b[39m'\u001b[39m\u001b[39mRSI\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m=\u001b[39mta\u001b[39m.\u001b[39mrsi(data\u001b[39m.\u001b[39mClose, length\u001b[39m=\u001b[39m\u001b[39m15\u001b[39m)\n\u001b[0;32m      3\u001b[0m data[\u001b[39m'\u001b[39m\u001b[39mEMAF\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m=\u001b[39mta\u001b[39m.\u001b[39mema(data\u001b[39m.\u001b[39mClose, length\u001b[39m=\u001b[39m\u001b[39m20\u001b[39m)\n\u001b[0;32m      4\u001b[0m data[\u001b[39m'\u001b[39m\u001b[39mEMAM\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m=\u001b[39mta\u001b[39m.\u001b[39mema(data\u001b[39m.\u001b[39mClose, length\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ta' is not defined"
     ]
    }
   ],
   "source": [
    "# Adding indicators\n",
    "data['RSI']=ta.rsi(data.Close, length=15)\n",
    "data['EMAF']=ta.ema(data.Close, length=20)\n",
    "data['EMAM']=ta.ema(data.Close, length=100)\n",
    "data['EMAS']=ta.ema(data.Close, length=150)\n",
    "\n",
    "data['Target'] = data['Adj Close']-data.Open\n",
    "data['Target'] = data['Target'].shift(-1)\n",
    "\n",
    "data['TargetClass'] = [1 if data.Target[i]>0 else 0 for i in range(len(data))]\n",
    "\n",
    "data['TargetNextClose'] = data['Adj Close'].shift(-1)\n",
    "\n",
    "data.dropna(inplace=True)\n",
    "data.reset_index(inplace = True)\n",
    "data.drop(['Volume', 'Close', 'Date'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b0e972",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = data.iloc[:, 0:11]#.values\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "#data_set.head(20)\n",
    "data_set\n",
    "#print(data_set.shape)\n",
    "#print(data.shape)\n",
    "#print(type(data_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb3a2c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Target column Categories\n",
    "#y =[1 if data.Open[i]>data.Close[i] else 0 for i in range(0, len(data))]\n",
    "#yi = [data.Open[i]-data.Close[i] for i in range(0, len(data))]\n",
    "#print(yi)\n",
    "#print(len(yi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9d38e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.99964654 -0.99952087 -0.99934439 ...  0.02003178  1.\n",
      "  -0.9986096 ]\n",
      " [-0.99924383 -0.99895064 -0.99891328 ...  0.0140514  -1.\n",
      "  -0.99927757]\n",
      " [-0.99859105 -0.99878137 -0.99915032 ...  0.01696932 -1.\n",
      "  -0.99930673]\n",
      " ...\n",
      " [-0.50586515 -0.51472239 -0.4996959  ...  0.02752984  1.\n",
      "  -0.50385334]\n",
      " [-0.50602125 -0.51298484 -0.49796991 ... -0.01007656 -1.\n",
      "  -0.50987003]\n",
      " [-0.50373312 -0.51182617 -0.50311619 ... -0.01158037 -1.\n",
      "  -0.5162095 ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range=(-1,1))\n",
    "data_set_scaled = sc.fit_transform(data_set)\n",
    "print(data_set_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99ca74fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2875\n",
      "[[[-0.99964654 -0.99952087 -0.99934439 ... -1.         -0.99829104\n",
      "   -0.99697281]\n",
      "  [-0.99924383 -0.99895064 -0.99891328 ... -0.99991529 -0.9983137\n",
      "   -0.99700873]\n",
      "  [-0.99859105 -0.99878137 -0.99915032 ... -0.99990669 -0.99835219\n",
      "   -0.99705562]\n",
      "  ...\n",
      "  [-0.99848387 -0.99874077 -0.9981596  ... -0.99843037 -0.99920992\n",
      "   -0.99937771]\n",
      "  [-0.99835431 -0.99873992 -0.9980953  ... -0.99847353 -0.99920921\n",
      "   -0.99937814]\n",
      "  [-0.99838805 -0.99864209 -0.99805003 ... -0.99849468 -0.99920424\n",
      "   -0.99937555]]\n",
      "\n",
      " [[-0.99924383 -0.99895064 -0.99891328 ... -0.99991529 -0.9983137\n",
      "   -0.99700873]\n",
      "  [-0.99859105 -0.99878137 -0.99915032 ... -0.99990669 -0.99835219\n",
      "   -0.99705562]\n",
      "  [-0.99926471 -0.9995424  -0.99910989 ... -0.99990187 -0.99839063\n",
      "   -0.99710238]\n",
      "  ...\n",
      "  [-0.99835431 -0.99873992 -0.9980953  ... -0.99847353 -0.99920921\n",
      "   -0.99937814]\n",
      "  [-0.99838805 -0.99864209 -0.99805003 ... -0.99849468 -0.99920424\n",
      "   -0.99937555]\n",
      "  [-0.99820225 -0.99863372 -0.99800848 ... -0.99852595 -0.99920227\n",
      "   -0.99937504]]\n",
      "\n",
      " [[-0.99859105 -0.99878137 -0.99915032 ... -0.99990669 -0.99835219\n",
      "   -0.99705562]\n",
      "  [-0.99926471 -0.9995424  -0.99910989 ... -0.99990187 -0.99839063\n",
      "   -0.99710238]\n",
      "  [-0.99930638 -0.99935997 -0.9990104  ... -0.99986798 -0.99842124\n",
      "   -0.99714356]\n",
      "  ...\n",
      "  [-0.99838805 -0.99864209 -0.99805003 ... -0.99849468 -0.99920424\n",
      "   -0.99937555]\n",
      "  [-0.99820225 -0.99863372 -0.99800848 ... -0.99852595 -0.99920227\n",
      "   -0.99937504]\n",
      "  [-0.99833337 -0.99876326 -0.99808789 ... -0.99856119 -0.99920199\n",
      "   -0.9993757 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-0.39050851 -0.38918256 -0.3947268  ... -0.28807657  0.14519231\n",
      "    0.31973977]\n",
      "  [-0.40388472 -0.41252561 -0.40352131 ... -0.29576892  0.13688721\n",
      "    0.3123595 ]\n",
      "  [-0.40901862 -0.4190302  -0.44003051 ... -0.30369436  0.12851554\n",
      "    0.30491456]\n",
      "  ...\n",
      "  [-0.50673017 -0.5145439  -0.50461701 ... -0.46821402 -0.32931821\n",
      "   -0.23493953]\n",
      "  [-0.50639564 -0.51341959 -0.49851114 ... -0.46875246 -0.33062001\n",
      "   -0.23665529]\n",
      "  [-0.50736588 -0.51460139 -0.4985393  ... -0.46908597 -0.33185927\n",
      "   -0.23832248]]\n",
      "\n",
      " [[-0.40388472 -0.41252561 -0.40352131 ... -0.29576892  0.13688721\n",
      "    0.3123595 ]\n",
      "  [-0.40901862 -0.4190302  -0.44003051 ... -0.30369436  0.12851554\n",
      "    0.30491456]\n",
      "  [-0.41756757 -0.40469327 -0.42963341 ... -0.31242367  0.11993673\n",
      "    0.29730607]\n",
      "  ...\n",
      "  [-0.50639564 -0.51341959 -0.49851114 ... -0.46875246 -0.33062001\n",
      "   -0.23665529]\n",
      "  [-0.50736588 -0.51460139 -0.4985393  ... -0.46908597 -0.33185927\n",
      "   -0.23832248]\n",
      "  [-0.50586515 -0.51472239 -0.4996959  ... -0.46940517 -0.33307816\n",
      "   -0.23997052]]\n",
      "\n",
      " [[-0.40901862 -0.4190302  -0.44003051 ... -0.30369436  0.12851554\n",
      "    0.30491456]\n",
      "  [-0.41756757 -0.40469327 -0.42963341 ... -0.31242367  0.11993673\n",
      "    0.29730607]\n",
      "  [-0.43377302 -0.44147323 -0.43104246 ... -0.32040361  0.11150818\n",
      "    0.28978457]\n",
      "  ...\n",
      "  [-0.50736588 -0.51460139 -0.4985393  ... -0.46908597 -0.33185927\n",
      "   -0.23832248]\n",
      "  [-0.50586515 -0.51472239 -0.4996959  ... -0.46940517 -0.33307816\n",
      "   -0.23997052]\n",
      "  [-0.50602125 -0.51298484 -0.49796991 ... -0.46945861 -0.33421661\n",
      "   -0.24155715]]]\n",
      "(2695, 180, 8)\n",
      "[[-0.99840891]\n",
      " [-0.9983614 ]\n",
      " [-0.998484  ]\n",
      " ...\n",
      " [-0.50385334]\n",
      " [-0.50987003]\n",
      " [-0.5162095 ]]\n",
      "(2695, 1)\n"
     ]
    }
   ],
   "source": [
    "# multiple feature from data provided to the model\n",
    "X = []\n",
    "#print(data_set_scaled[0].size)\n",
    "#data_set_scaled=data_set.values\n",
    "backcandles = 180\n",
    "print(data_set_scaled.shape[0])\n",
    "for j in range(8):#data_set_scaled[0].size):#2 columns are target not X\n",
    "    X.append([])\n",
    "    for i in range(backcandles, data_set_scaled.shape[0]):#backcandles+2\n",
    "        X[j].append(data_set_scaled[i-backcandles:i, j])\n",
    "\n",
    "#move axis from 0 to position 2\n",
    "X=np.moveaxis(X, [0], [2])\n",
    "\n",
    "#Erase first elements of y because of backcandles to match X length\n",
    "#del(yi[0:backcandles])\n",
    "#X, yi = np.array(X), np.array(yi)\n",
    "# Choose -1 for last column, classification else -2...\n",
    "X, yi =np.array(X), np.array(data_set_scaled[backcandles:,-1])\n",
    "y=np.reshape(yi,(len(yi),1))\n",
    "#y=sc.fit_transform(yi)\n",
    "#X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "print(X)\n",
    "print(X.shape)\n",
    "print(y)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c01b699a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#also comprehensions for X\n",
    "#X = np.array([data_set_scaled[i-backcandles:i,:4].copy() for i in range(backcandles,len(data_set_scaled))])\n",
    "#print(X)\n",
    "#print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2a87918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2156\n",
      "(2156, 180, 8)\n",
      "(539, 180, 8)\n",
      "(2156, 1)\n",
      "(539, 1)\n",
      "(2156, 1)\n"
     ]
    }
   ],
   "source": [
    "# split data into train test sets\n",
    "splitlimit = int(len(X)*0.8)\n",
    "print(splitlimit)\n",
    "X_train, X_test = X[:splitlimit], X[splitlimit:]\n",
    "y_train, y_test = y[:splitlimit], y[splitlimit:]\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9867161a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_input (InputLayer)     [(None, 180, 8)]          0         \n",
      "                                                                 \n",
      " first_layer (LSTM)          (None, 100)               43600     \n",
      "                                                                 \n",
      " dense_layer (Dense)         (None, 1)                 101       \n",
      "                                                                 \n",
      " output (Activation)         (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 43,701\n",
      "Trainable params: 43,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "61/61 [==============================] - 24s 231ms/step - loss: 0.0948 - val_loss: 0.0470\n",
      "Epoch 2/50\n",
      "61/61 [==============================] - 12s 194ms/step - loss: 0.0016 - val_loss: 0.0441\n",
      "Epoch 3/50\n",
      "61/61 [==============================] - 12s 200ms/step - loss: 9.9174e-04 - val_loss: 0.0433\n",
      "Epoch 4/50\n",
      "61/61 [==============================] - 12s 195ms/step - loss: 7.0231e-04 - val_loss: 0.0433\n",
      "Epoch 5/50\n",
      "61/61 [==============================] - 13s 213ms/step - loss: 5.5832e-04 - val_loss: 0.0429\n",
      "Epoch 6/50\n",
      "61/61 [==============================] - 14s 223ms/step - loss: 4.9958e-04 - val_loss: 0.0411\n",
      "Epoch 7/50\n",
      "61/61 [==============================] - 13s 209ms/step - loss: 4.5209e-04 - val_loss: 0.0399\n",
      "Epoch 8/50\n",
      "61/61 [==============================] - 12s 201ms/step - loss: 4.1531e-04 - val_loss: 0.0390\n",
      "Epoch 9/50\n",
      "61/61 [==============================] - 12s 197ms/step - loss: 3.9158e-04 - val_loss: 0.0378\n",
      "Epoch 10/50\n",
      "61/61 [==============================] - 12s 197ms/step - loss: 3.7701e-04 - val_loss: 0.0367\n",
      "Epoch 11/50\n",
      "61/61 [==============================] - 12s 197ms/step - loss: 3.4004e-04 - val_loss: 0.0363\n",
      "Epoch 12/50\n",
      "61/61 [==============================] - 12s 195ms/step - loss: 3.3363e-04 - val_loss: 0.0355\n",
      "Epoch 13/50\n",
      "61/61 [==============================] - 12s 197ms/step - loss: 3.1815e-04 - val_loss: 0.0353\n",
      "Epoch 14/50\n",
      "61/61 [==============================] - 12s 202ms/step - loss: 2.9929e-04 - val_loss: 0.0351\n",
      "Epoch 15/50\n",
      "61/61 [==============================] - 12s 200ms/step - loss: 3.1182e-04 - val_loss: 0.0353\n",
      "Epoch 16/50\n",
      "61/61 [==============================] - 12s 201ms/step - loss: 3.1835e-04 - val_loss: 0.0340\n",
      "Epoch 17/50\n",
      "61/61 [==============================] - 12s 196ms/step - loss: 3.0320e-04 - val_loss: 0.0351\n",
      "Epoch 18/50\n",
      "61/61 [==============================] - 12s 201ms/step - loss: 2.9747e-04 - val_loss: 0.0350\n",
      "Epoch 19/50\n",
      "61/61 [==============================] - 13s 219ms/step - loss: 2.8944e-04 - val_loss: 0.0351\n",
      "Epoch 20/50\n",
      "61/61 [==============================] - 13s 211ms/step - loss: 2.8946e-04 - val_loss: 0.0354\n",
      "Epoch 21/50\n",
      "61/61 [==============================] - 13s 215ms/step - loss: 2.9307e-04 - val_loss: 0.0352\n",
      "Epoch 22/50\n",
      "61/61 [==============================] - 13s 209ms/step - loss: 3.1007e-04 - val_loss: 0.0348\n",
      "Epoch 23/50\n",
      "61/61 [==============================] - 13s 220ms/step - loss: 3.0521e-04 - val_loss: 0.0355\n",
      "Epoch 24/50\n",
      "61/61 [==============================] - 13s 215ms/step - loss: 2.6688e-04 - val_loss: 0.0357\n",
      "Epoch 25/50\n",
      "61/61 [==============================] - 12s 200ms/step - loss: 2.7138e-04 - val_loss: 0.0362\n",
      "Epoch 26/50\n",
      "61/61 [==============================] - 12s 197ms/step - loss: 2.7000e-04 - val_loss: 0.0361\n",
      "Epoch 27/50\n",
      "61/61 [==============================] - 13s 205ms/step - loss: 2.6212e-04 - val_loss: 0.0359\n",
      "Epoch 28/50\n",
      "61/61 [==============================] - 12s 204ms/step - loss: 2.8353e-04 - val_loss: 0.0375\n",
      "Epoch 29/50\n",
      "61/61 [==============================] - 12s 197ms/step - loss: 2.8299e-04 - val_loss: 0.0377\n",
      "Epoch 30/50\n",
      "61/61 [==============================] - 12s 203ms/step - loss: 3.2026e-04 - val_loss: 0.0364\n",
      "Epoch 31/50\n",
      "61/61 [==============================] - 12s 201ms/step - loss: 2.6686e-04 - val_loss: 0.0376\n",
      "Epoch 32/50\n",
      "61/61 [==============================] - 12s 199ms/step - loss: 2.6953e-04 - val_loss: 0.0372\n",
      "Epoch 33/50\n",
      "61/61 [==============================] - 12s 197ms/step - loss: 2.5865e-04 - val_loss: 0.0372\n",
      "Epoch 34/50\n",
      "61/61 [==============================] - 12s 199ms/step - loss: 2.5279e-04 - val_loss: 0.0381\n",
      "Epoch 35/50\n",
      "61/61 [==============================] - 12s 195ms/step - loss: 2.6077e-04 - val_loss: 0.0388\n",
      "Epoch 36/50\n",
      "61/61 [==============================] - 12s 196ms/step - loss: 2.6384e-04 - val_loss: 0.0379\n",
      "Epoch 37/50\n",
      "61/61 [==============================] - 12s 197ms/step - loss: 2.5817e-04 - val_loss: 0.0384\n",
      "Epoch 38/50\n",
      "61/61 [==============================] - 12s 198ms/step - loss: 2.5239e-04 - val_loss: 0.0392\n",
      "Epoch 39/50\n",
      "61/61 [==============================] - 12s 198ms/step - loss: 2.5720e-04 - val_loss: 0.0380\n",
      "Epoch 40/50\n",
      "61/61 [==============================] - 12s 197ms/step - loss: 2.6364e-04 - val_loss: 0.0388\n",
      "Epoch 41/50\n",
      "61/61 [==============================] - 12s 202ms/step - loss: 2.5041e-04 - val_loss: 0.0387\n",
      "Epoch 42/50\n",
      "61/61 [==============================] - 12s 198ms/step - loss: 2.4663e-04 - val_loss: 0.0400\n",
      "Epoch 43/50\n",
      "61/61 [==============================] - 13s 209ms/step - loss: 2.5601e-04 - val_loss: 0.0402\n",
      "Epoch 44/50\n",
      "61/61 [==============================] - 13s 206ms/step - loss: 2.6386e-04 - val_loss: 0.0400\n",
      "Epoch 45/50\n",
      "61/61 [==============================] - 13s 210ms/step - loss: 2.4081e-04 - val_loss: 0.0396\n",
      "Epoch 46/50\n",
      "61/61 [==============================] - 13s 208ms/step - loss: 2.6226e-04 - val_loss: 0.0396\n",
      "Epoch 47/50\n",
      "61/61 [==============================] - 13s 211ms/step - loss: 2.6426e-04 - val_loss: 0.0404\n",
      "Epoch 48/50\n",
      "61/61 [==============================] - 13s 205ms/step - loss: 2.5464e-04 - val_loss: 0.0397\n",
      "Epoch 49/50\n",
      "61/61 [==============================] - 12s 198ms/step - loss: 2.2691e-04 - val_loss: 0.0403\n",
      "Epoch 50/50\n",
      "61/61 [==============================] - 12s 198ms/step - loss: 2.4314e-04 - val_loss: 0.0408\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1af6d53ba60>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Dense\n",
    "from keras.layers import TimeDistributed\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import optimizers\n",
    "from keras.callbacks import History\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout, LSTM, Input, Activation, concatenate\n",
    "import numpy as np\n",
    "#tf.random.set_seed(20)\n",
    "np.random.seed(10)\n",
    "\n",
    "lstm_input = Input(shape=(backcandles, 8), name='lstm_input')\n",
    "inputs = LSTM(100, name='first_layer')(lstm_input)\n",
    "inputs = Dense(1, name='dense_layer')(inputs)\n",
    "output = Activation('linear', name='output')(inputs)\n",
    "model = Model(inputs=lstm_input, outputs=output)\n",
    "adam = optimizers.Adam()\n",
    "model.compile(optimizer=adam, loss=\"mean_squared_error\")\n",
    "print(model.summary())\n",
    "model.fit(x=X_train, y=y_train, batch_size=32, epochs=50, shuffle=True, validation_split = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08324ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 2s 76ms/step\n",
      "[-0.06674043] [-0.03002807]\n",
      "[-0.0691288] [-0.00269165]\n",
      "[-0.07954112] [-0.01093118]\n",
      "[-0.08071733] [0.0104378]\n",
      "[-0.08294454] [-0.02175932]\n",
      "[-0.0782081] [-0.03523458]\n",
      "[-0.08314992] [-0.03166188]\n",
      "[-0.09129575] [-0.06259043]\n",
      "[-0.09735923] [-0.07325584]\n",
      "[-0.11034627] [-0.06994422]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "#y_pred=np.where(y_pred > 0.43, 1,0)\n",
    "for i in range(10):\n",
    "   print(y_pred[i], y_test[i])\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47c29ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the MAPE is :  52.129596374886155\n"
     ]
    }
   ],
   "source": [
    "def MAPE(Y_actual,Y_Predicted):\n",
    "    mape = np.mean(np.abs((Y_actual - Y_Predicted)/Y_actual))*100\n",
    "    return mape\n",
    "print(\"the MAPE is : \", MAPE(y_test,y_pred))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67f5e31a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m8\u001b[39m,\u001b[39m8\u001b[39m))\n\u001b[0;32m      2\u001b[0m plt\u001b[39m.\u001b[39mplot(y_test, color \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mblue\u001b[39m\u001b[39m'\u001b[39m, label \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mTest\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m plt\u001b[39m.\u001b[39mplot(y_pred, color \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mred\u001b[39m\u001b[39m'\u001b[39m, label \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mpred\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.plot(y_test, color = 'blue', label = 'Test')\n",
    "plt.plot(y_pred, color = 'red', label = 'pred')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "67e0cbc25fa4f5baaacba1240f401bc655b640f8e15cfc935dfee2e63491bdf4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
