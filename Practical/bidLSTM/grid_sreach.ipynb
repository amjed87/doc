{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 4s 5ms/step - loss: 3.8483e-05 - mean_absolute_error: 0.0037\n",
      "71/71 [==============================] - 4s 5ms/step - loss: 2.4258e-05 - mean_absolute_error: 0.0028\n",
      "71/71 [==============================] - 4s 5ms/step - loss: 1.3154e-05 - mean_absolute_error: 0.0017\n",
      "71/71 [==============================] - 6s 7ms/step - loss: 7.8108e-05 - mean_absolute_error: 0.0057\n",
      "71/71 [==============================] - 4s 5ms/step - loss: 2.8476e-05 - mean_absolute_error: 0.0035\n",
      "71/71 [==============================] - 6s 6ms/step - loss: 3.7215e-05 - mean_absolute_error: 0.0042\n",
      "71/71 [==============================] - 7s 7ms/step - loss: 2.3834e-04 - mean_absolute_error: 0.0087\n",
      "71/71 [==============================] - 7s 7ms/step - loss: 2.7913e-05 - mean_absolute_error: 0.0035\n",
      "71/71 [==============================] - 7s 6ms/step - loss: 3.2039e-05 - mean_absolute_error: 0.0043\n",
      "71/71 [==============================] - 3s 5ms/step - loss: 4.2595e-05 - mean_absolute_error: 0.0041\n",
      "71/71 [==============================] - 4s 6ms/step - loss: 6.9079e-05 - mean_absolute_error: 0.0050\n",
      "71/71 [==============================] - 4s 5ms/step - loss: 4.5816e-05 - mean_absolute_error: 0.0031\n",
      "71/71 [==============================] - 4s 5ms/step - loss: 7.3574e-05 - mean_absolute_error: 0.0048\n",
      "71/71 [==============================] - 6s 6ms/step - loss: 5.7222e-05 - mean_absolute_error: 0.0061\n",
      "71/71 [==============================] - 5s 6ms/step - loss: 2.7223e-05 - mean_absolute_error: 0.0031\n",
      "71/71 [==============================] - 7s 8ms/step - loss: 1.1142e-04 - mean_absolute_error: 0.0077\n",
      "71/71 [==============================] - 7s 7ms/step - loss: 3.1184e-05 - mean_absolute_error: 0.0030\n",
      "71/71 [==============================] - 6s 7ms/step - loss: 3.0189e-05 - mean_absolute_error: 0.0034\n",
      "71/71 [==============================] - 4s 5ms/step - loss: 8.1573e-05 - mean_absolute_error: 0.0061\n",
      "71/71 [==============================] - 4s 6ms/step - loss: 3.1299e-05 - mean_absolute_error: 0.0036\n",
      "71/71 [==============================] - 3s 5ms/step - loss: 2.3150e-05 - mean_absolute_error: 0.0030\n",
      "71/71 [==============================] - 6s 6ms/step - loss: 9.2006e-05 - mean_absolute_error: 0.0076\n",
      "71/71 [==============================] - 5s 6ms/step - loss: 7.1543e-05 - mean_absolute_error: 0.0050\n",
      "71/71 [==============================] - 5s 6ms/step - loss: 2.9525e-05 - mean_absolute_error: 0.0038\n",
      "71/71 [==============================] - 8s 7ms/step - loss: 8.1799e-05 - mean_absolute_error: 0.0060\n",
      "71/71 [==============================] - 7s 9ms/step - loss: 6.1252e-05 - mean_absolute_error: 0.0045\n",
      "71/71 [==============================] - 7s 11ms/step - loss: 4.0009e-05 - mean_absolute_error: 0.0045\n",
      "71/71 [==============================] - 4s 7ms/step - loss: 5.3041e-05 - mean_absolute_error: 0.0033\n",
      "71/71 [==============================] - 3s 6ms/step - loss: 1.9098e-05 - mean_absolute_error: 0.0028\n",
      "71/71 [==============================] - 3s 7ms/step - loss: 2.4710e-05 - mean_absolute_error: 0.0033\n",
      "71/71 [==============================] - 5s 8ms/step - loss: 5.6044e-05 - mean_absolute_error: 0.0039\n",
      "71/71 [==============================] - 4s 7ms/step - loss: 3.2998e-05 - mean_absolute_error: 0.0038\n",
      "71/71 [==============================] - 5s 8ms/step - loss: 3.2449e-05 - mean_absolute_error: 0.0035\n",
      "71/71 [==============================] - 7s 10ms/step - loss: 2.1388e-04 - mean_absolute_error: 0.0112\n",
      "71/71 [==============================] - 7s 9ms/step - loss: 3.2570e-05 - mean_absolute_error: 0.0044\n",
      "71/71 [==============================] - 6s 11ms/step - loss: 2.0005e-05 - mean_absolute_error: 0.0029\n",
      "71/71 [==============================] - 4s 6ms/step - loss: 3.2352e-05 - mean_absolute_error: 0.0030\n",
      "71/71 [==============================] - 3s 6ms/step - loss: 5.1777e-05 - mean_absolute_error: 0.0034\n",
      "71/71 [==============================] - 4s 7ms/step - loss: 1.3363e-04 - mean_absolute_error: 0.0071\n",
      "71/71 [==============================] - 5s 10ms/step - loss: 4.7605e-05 - mean_absolute_error: 0.0032\n",
      "71/71 [==============================] - 4s 12ms/step - loss: 2.3146e-05 - mean_absolute_error: 0.0026\n",
      "71/71 [==============================] - 6s 11ms/step - loss: 4.5120e-05 - mean_absolute_error: 0.0039\n",
      "71/71 [==============================] - 7s 13ms/step - loss: 5.1067e-05 - mean_absolute_error: 0.0039\n",
      "71/71 [==============================] - 6s 10ms/step - loss: 7.4338e-05 - mean_absolute_error: 0.0049\n",
      "71/71 [==============================] - 6s 13ms/step - loss: 1.5502e-05 - mean_absolute_error: 0.0024\n",
      "71/71 [==============================] - 4s 9ms/step - loss: 5.6219e-05 - mean_absolute_error: 0.0039\n",
      "71/71 [==============================] - 3s 7ms/step - loss: 6.4594e-05 - mean_absolute_error: 0.0057\n",
      "71/71 [==============================] - 4s 9ms/step - loss: 2.3931e-05 - mean_absolute_error: 0.0034\n",
      "71/71 [==============================] - 6s 12ms/step - loss: 5.4111e-05 - mean_absolute_error: 0.0039\n",
      "71/71 [==============================] - 5s 11ms/step - loss: 3.6598e-05 - mean_absolute_error: 0.0034\n",
      "71/71 [==============================] - 6s 12ms/step - loss: 2.3760e-05 - mean_absolute_error: 0.0028\n",
      "71/71 [==============================] - 8s 14ms/step - loss: 9.3110e-05 - mean_absolute_error: 0.0047\n",
      "71/71 [==============================] - 7s 15ms/step - loss: 4.5010e-05 - mean_absolute_error: 0.0025\n",
      "71/71 [==============================] - 8s 16ms/step - loss: 8.5089e-05 - mean_absolute_error: 0.0056\n",
      "71/71 [==============================] - 5s 13ms/step - loss: 9.0090e-05 - mean_absolute_error: 0.0067\n",
      "71/71 [==============================] - 4s 12ms/step - loss: 5.2269e-05 - mean_absolute_error: 0.0036\n",
      "71/71 [==============================] - 4s 12ms/step - loss: 2.0493e-05 - mean_absolute_error: 0.0034\n",
      "71/71 [==============================] - 6s 18ms/step - loss: 4.5424e-05 - mean_absolute_error: 0.0047\n",
      "71/71 [==============================] - 6s 19ms/step - loss: 6.9053e-05 - mean_absolute_error: 0.0040\n",
      "71/71 [==============================] - 7s 21ms/step - loss: 3.2863e-05 - mean_absolute_error: 0.0043\n",
      "71/71 [==============================] - 9s 31ms/step - loss: 4.1023e-05 - mean_absolute_error: 0.0031\n",
      "71/71 [==============================] - 29s 50ms/step - loss: 5.6639e-05 - mean_absolute_error: 0.0048\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 63\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[39mfor\u001b[39;00m epochs \u001b[39min\u001b[39;00m param_grid[\u001b[39m'\u001b[39m\u001b[39mepochs\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[0;32m     62\u001b[0m     model \u001b[39m=\u001b[39m create_lstm_model(units\u001b[39m=\u001b[39munits, dropout_rate\u001b[39m=\u001b[39mdropout_rate, num_hidden_layers\u001b[39m=\u001b[39mnum_hidden_layers)\n\u001b[1;32m---> 63\u001b[0m     model\u001b[39m.\u001b[39;49mfit(X_train, y_train, epochs\u001b[39m=\u001b[39;49mepochs, batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m, verbose\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n\u001b[0;32m     64\u001b[0m     score \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mevaluate(X_train, y_train)[\u001b[39m0\u001b[39m]\n\u001b[0;32m     65\u001b[0m     \u001b[39mif\u001b[39;00m score \u001b[39m<\u001b[39m best_score:\n",
      "File \u001b[1;32mc:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py:1655\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1653\u001b[0m \u001b[39m# No error, now safe to assign to logs.\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m logs \u001b[39m=\u001b[39m tmp_logs\n\u001b[1;32m-> 1655\u001b[0m end_step \u001b[39m=\u001b[39m step \u001b[39m+\u001b[39m data_handler\u001b[39m.\u001b[39;49mstep_increment\n\u001b[0;32m   1656\u001b[0m callbacks\u001b[39m.\u001b[39mon_train_batch_end(end_step, logs)\n\u001b[0;32m   1657\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstop_training:\n",
      "File \u001b[1;32mc:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\data_adapter.py:1391\u001b[0m, in \u001b[0;36mDataHandler.step_increment\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1388\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_current_step \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m steps_remaining\n\u001b[0;32m   1389\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_steps_per_execution\u001b[39m.\u001b[39massign(original_spe)\n\u001b[1;32m-> 1391\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[0;32m   1392\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstep_increment\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m   1393\u001b[0m     \u001b[39m\"\"\"The number to increment the step for `on_batch_end` methods.\"\"\"\u001b[39;00m\n\u001b[0;32m   1394\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_step_increment\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas_ta as ta\n",
    "import yfinance as yf\n",
    "from datetime import timedelta\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "# Read the data\n",
    "data_csv = pd.read_csv('btc-2015-2022_case1.csv')\n",
    "data_csv.dropna(inplace=True)\n",
    "data_csv.set_index('Date', inplace=True)\n",
    "data_csv.dropna(inplace=True)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "train_df = data_csv[:int(len(data_csv) * 0.8)]\n",
    "test_df = data_csv[int(len(data_csv) * 0.8):]\n",
    "\n",
    "# Preprocess the data\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(train_df.drop(['Adj Close'], axis=1).values)\n",
    "y_train = scaler.fit_transform(train_df['Adj Close'].values.reshape(-1, 1))\n",
    "X_test = scaler.fit_transform(test_df.drop(['Adj Close'], axis=1).values)\n",
    "y_test = scaler.fit_transform(test_df['Adj Close'].values.reshape(-1, 1))\n",
    "\n",
    "# Reshape the data\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "# Define the LSTM model function\n",
    "def create_lstm_model(units=100, dropout_rate=0.2, num_hidden_layers=1):\n",
    "    model = Sequential()\n",
    "    for _ in range(num_hidden_layers):\n",
    "        model.add(Bidirectional(LSTM(units, input_shape=(X_train.shape[1], X_train.shape[2]),\n",
    "                                     return_sequences=True, activation='tanh')))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "    model.add(Bidirectional(LSTM(units, activation='tanh')))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_absolute_error'])\n",
    "    return model\n",
    "\n",
    "# Define the hyperparameter grid for grid search\n",
    "param_grid = {\n",
    "    'units': [50, 75, 100],\n",
    "    'dropout_rate': [0.2, 0.25, 0.3],\n",
    "    'num_hidden_layers': [1, 2, 3],\n",
    "    'epochs': [100, 500, 1000]\n",
    "}\n",
    "\n",
    "# Perform grid search\n",
    "best_score = float(\"inf\")\n",
    "best_params = {}\n",
    "for units in param_grid['units']:\n",
    "    for dropout_rate in param_grid['dropout_rate']:\n",
    "        for num_hidden_layers in param_grid['num_hidden_layers']:\n",
    "            for epochs in param_grid['epochs']:\n",
    "                model = create_lstm_model(units=units, dropout_rate=dropout_rate, num_hidden_layers=num_hidden_layers)\n",
    "                model.fit(X_train, y_train, epochs=epochs, batch_size=32, verbose=0)\n",
    "                score = model.evaluate(X_train, y_train)[0]\n",
    "                if score < best_score:\n",
    "                    best_score = score\n",
    "                    best_params = {\n",
    "                        'units': units,\n",
    "                        'dropout_rate': dropout_rate,\n",
    "                        'num_hidden_layers': num_hidden_layers,\n",
    "                        'epochs': epochs\n",
    "                    }\n",
    "\n",
    "# Access the best hyperparameters\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "# Train and evaluate the best model\n",
    "best_model = create_lstm_model(units=best_params['units'],\n",
    "                               dropout_rate=best_params['dropout_rate'],\n",
    "                               num_hidden_layers=best_params['num_hidden_layers'])\n",
    "best_model.fit(X_train, y_train, epochs=best_params['epochs'], batch_size=32)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred_train = best_model.predict(X_train)\n",
    "y_pred_val = best_model.predict(X_test)\n",
    "\n",
    "# Perform evaluation metrics\n",
    "accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "accuracy_val = accuracy_score(y_test, y_pred_val)\n",
    "precision_train = precision_score(y_train, y_pred_train)\n",
    "precision_val = precision_score(y_test, y_pred_val)\n",
    "recall_train = recall_score(y_train, y_pred_train)\n",
    "recall_val = recall_score(y_test, y_pred_val)\n",
    "f1_train = f1_score(y_train, y_pred_train)\n",
    "f1_val = f1_score(y_test, y_pred_val)\n",
    "\n",
    "# Print evaluation results\n",
    "print(\"Training Set:\")\n",
    "print(\"Accuracy:\", accuracy_train)\n",
    "print(\"Precision:\", precision_train)\n",
    "print(\"Recall:\", recall_train)\n",
    "print(\"F1-Score:\", f1_train)\n",
    "\n",
    "print(\"Validation Set:\")\n",
    "print(\"Accuracy:\", accuracy_val)\n",
    "print(\"Precision:\", precision_val)\n",
    "print(\"Recall:\", recall_val)\n",
    "print(\"F1-Score:\", f1_val)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
